# Redis

[toc]

## Redis概念

Redis（Remote Dictionary Server )，即远程字典服务.一个开源的使用ANSI [C语言](https://baike.baidu.com/item/C语言)编写、支持网络、可基于内存亦可持久化的日志型、Key-Value[数据库](https://baike.baidu.com/item/数据库/103728)，并提供多种语言的API。

> Redis能干什么

1. 内存存储,持久化,内存中断电即失,所以持久化很重要(rdb,aof)
2. 效率高,可以用于高速缓存
3. 发布订阅系统
4. 地图信息分析
5. 计时器,计数器(浏览量)
6. **Redis 除了做缓存之外，Redis 也经常用来做分布式锁，甚至是消息队列。**
7. .......


## 基础知识

redis默认有16个数据库,默认使用第0个数据



```shell
# 切换数据库
127.0.0.1:6379> select 2
OK
127.0.0.1:6379[2]>

# 查看当前空间
127.0.0.1:6379[2]> select 0                                                                 OK
127.0.0.1:6379> dbsize                                                                       (integer) 6
```



> redis是单线程的

官方表示,Redis是基于内存操作,CPU不是Redis性能瓶颈,Redis的瓶颈是机器的内存和网络带宽,既然可以用单线程实现,就使用单线程了

## 五大数据类型

### Redis-Key

```
1.exists name # 判断当前key是否存在 存在为1 反之为0

2.move name # 移除当前key

 3.expire name 10 # 设置key的过期时间,单位是秒

4.ttl name # 查看当前key的剩余时间

5.type name # 查看key的类型
```

#### String

```bash
1.append name “shanjiao” # 追加字符串,如果当前key不存在相当于setkey
2.strlen name # 查看指定key的长度
3.incr views # views自增1
4.decr views # views自减1
5.incrby views 10 # 自定义设置自增步长
6.decrby views 5 # 自定义设置自减步长
```

String类似的使用场景: value除了是我们的字符串还可以是我们的数字

- 计数器
- 统计多单位的数量
- 粉丝数*
- 对象缓存存储

#### List

1. **介绍** ：**list** 即是 **链表**。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且且可以灵活调整链表长度，但是链表的随机访问困难。许多高级编程语言都内置了链表的实现比如 Java 中的 **LinkedList**，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 list 的实现为一个 **双向链表**，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。
2. **常用命令:** `rpush,lpop,lpush,rpop,lrange、llen` 等。
3. **应用场景:** 发布与订阅或者说消息队列、慢查询。

在redis中,我们可以把list玩成,栈,队列,阻塞队列!

所有的list命令都是以 l 开头的

> 小结

- 他实际上是一个链表,before Bode after, left, right 都可以插入值
- 如果key不存在,创建新的链表
- 如果key存在,新增内容
- 如果移除了所有值,空链表,也就代表不存在
- 在两边插入或者改动值,效率最高!中间元素,相对俩手效率会低一点~

消息队列,消息排队!(Lpush Rpop) , 栈 (Lpush Lpop)!

**通过 `rpush/lpop` 实现队列：**

**通过 `rpush/rpop` 实现栈：**

#### Set

1. **介绍 ：** set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。
2. **常用命令：** `sadd,spop,smembers,sismember,scard,sinterstore,sunion` 等。
3. **应用场景:** 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景

set中的值是不能重复的

#### ZSet

1. **介绍：** 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。
2. **常用命令：** `zadd,zcard,zscore,zrange,zrevrange,zrem` 等。
3. **应用场景：** 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。

在set的基础上,增加了一个值,set k1 v1 zset k1 score1 v1

#### Hash

1. **介绍** ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，**特别适合用于存储对象**，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。
2. **常用命令：** `hset,hmset,hexists,hget,hgetall,hkeys,hvals` 等。
3. **应用场景:** 系统中对象数据的存储。

相当于Map集合,key-value!只是value是map,key-map

set myhash field codeyuaiiao

```bash
# hset 添加元素(一个&多个)
# hget 获取元素
# hmget 获取多个指定字段值
# hgetall 获取全部元素
# hdel 删除元素(一个&多个)
```

## 三种特殊数据类型

### geospatial (地理位置)

### hyperloglog (求基数)

> 什么是基数?

A{1,3.,5,7,9}

B{1,3,5,7,9,9}

基数(不重复的元素) =AB合并=5 , 可以接受误差

> 简介

Redis 2.8.9 版本就跟新了Hyperloglog数据结构!

Redis Hyperloglog 基数统计的算法!

优点: 占用的内存是固定的, 2^64 不同的元素的基数,只需要12kb的内存即可,如果从内存角度来比较,且允许有误差(0.81%)Hyperloglog首选

**网页的UV(一个人访问一个网站多次,但是还是算作一个人!)**

传统的方式,set保存用户的id ,然后就可以统计set中元素数量作为标准!

set集合(无序,不重复)

这个方式如果保存大量的用户id,就会比较麻烦! 我们的目的是为了技术,而不是保存用户id

### bitmap (判断状态)

统计用户信息(活跃,不活跃) (登录,未登录)

打卡(打卡,未打卡)

两个状态的都可以使用bitmap

bitmap 位图 , 数据结构! 都是操作二进制位来进行记录的,就只有0和1两个状态

1字节 = 8bit

## 四.事务

Redis事务本质: 一组命令的集合! 一个事务中的所有命令都会被序列化,在事务执行过程中,会按照顺序执行!

一次性,顺序性,排他性! 执行一系列的命令!

```
------队列 set get set 执行-----
```

Redis 事务没有隔离级别的概念!

所有的命令在事务中,并没有直接被执行,只有发起执行命令的时候才会执行! Exec

Redis单条命令是保证原子性的,但是事务不保证原子性!

### redis的事务命令:

- 开启事务(multi)
- 命令入队(—正常命令—)
- 执行事务(exec)

### 正常执行事务

## 八.Redis持久化

### RDB(Redis DataBase)

在主从复制中,rdb就是备用了! 从机上面!

在指定的时间间隔内将内存中的数据集快照写入磁盘,也就是行话讲的Snapshot快照,它恢复时是将快照文件直接读到内存里.

Redis会单独创建(fork)一个子进程来进行持久化,会先将数据写入到一个临时文件中, 带持久化过程都结束了,再用这个临时文件替换上次持久化好的文件. 整个过程中,主进程是不进行任何IO操作的.这就确保了极高的性能.如果需要进行大规模数据的恢复,且对于数据恢复的完整性不是非常敏感.那RDB方式要不AOF方式更加的高效.RDB的缺点是最后一次持久化后的数据可能丢失. 我们默认的就是RDB, 一般情况下不需要修改这个配置!

RDB保存的文件是,dump.rdb都是在我们的配置文件中快照中进行配置的!

> 触发机制

1. save 的规则满足的情况下,会自动触发rdb规则
2. 执行flushall命令 , 也会触发我们的rdb 规则!
3. 退出redis,也会产生rdb文件!

备份就会自动生成一个dump.rdb

> 如何恢复rdb文件!

1. 只需要将rdb 文件放在我们redis启动目录就可以,redis启动的时候会自动检查dump.rdb恢复其中的数据!

2. 查看需要存在的位置

3. ```bash
     127.0.0.1:6379> config get dir
     1) "dir"
     2) "/usr/local/bin" # 入伙在这个目录下存在dump.rdb 文件,启动就会自动恢复其中的数据
    123
    ```

4. 默认的配置就可以了

> 优点&缺点

**优点:**

1. 适合大规模的数据恢复!
2. 对数据的完整性要求不高!

**缺点:**

1. 需要一定的时间间隔进行操作! 如果redis意外宕机了,这个最后一个修改的数据就没有了!
2. fork进程的时候,会占用一定的内容空间!

### AOF(Append Only File)

将我们的所有命令都记录下来,history , 恢复的时候就把这个文件全部在执行一遍

> 是什么

以日志的形式来记录每个写操作,将Redis执行过的所有指令记录下来(读操作不记录) , 只许追加文件但不可以改写文件,redis 启动之初会读取改文件重新构建数据,换言之,redis重启的话就跟据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作

Aof保存的是 appendonly.aof文件

> append

默认是不开启的,我们需要手动进行配置! 我们只需要将appendonly 改为yes就开启了aof!

重启,redis 就可以生效了!

如果这个aof文件有错位,这时候 redis是启动不起来的,我们需要修复这个aof文件

redis 给我提供了一个工具`redis-check-aof --fix`

如果文件正常,重启就可以直接恢复了!

> 重写规则说明

aof默认就是文件的无限追加 , 文件会越来越大!

如果aof文件大于64m,太大了 ! fork一个新的进程来将我们的文件进行重写!

> 优点&缺点

```bash
appendonly no # 默认是不开启aof模式的, 默认是使用rdb方式持久化的,再大部分情况下,rdb完全够用!
Appendfilename "appendonly.aof" # 持久化的文件的名字

# appendfsync always # 每次修改都会sync .消耗性能
appendfsync everysec # 每秒执行一次sync,可能会丢失这1s的数据!
# appendfsync no     # 不执行sync ,这个时候操作系统自己同步数据,速度最快!
```

**优点:**

1. 每一次修改都同步,文件的完整性会更好!
2. 每秒同步一次,可能会丢失一秒的数据
3. 从不同步,效率最高!

**缺点:**

1. 相对于数据文件来说, aof远远大于rdb,修复的速度也比rdb慢!
2. aof运行效率也要比rdb慢,所以我们redis默认的配置就是rdb持久化!

## 九.Redis发布订阅

Redis 发布订阅(pub/sub)是一种消息通信模式: 发送者(pub)发送消息,订阅者(sub)接受消息.微博,微信,关注系统!

Redis 客户端可以订阅任意数量的频道.

订阅/发布消息图:

第一个: 消息发送者, 第二个 :频道 第三个 :消息订阅者!

## 十.Redis主从复制

### 概念

主从复制,是指将一台Redis服务器的数据,复制到其他的Redis服务器.前者称为主节点(master/leader),后者称为从节点(slave/follower);==数据的复制是单向的,只能由主节点到从节点.==Master以写为主,Slave以读为主.

默认情况下,每台Redis服务器都是主节点;且一个主节点可以有多个从节点(或没有从节点),但一个从节点只能有一个主节点.

**主从复制的作用主要包括:**

1. 数据冗余: 主从复制实现了数据的热备份,使持久化之外的一种数据冗余方式.
2. 故障恢复:当主节点出现问题是,可以由从节点提供服务,实现快速的故障恢复;实际上是一种服务的冗余.
3. 负载均衡: 在主从复制的基础上,配合读写分离,可以由主节点提供写服务(既写Redis数据是应用连接主节点,读Redis数据时应用连接从节点),分担服务器负载;尤其是在写少读多的场景下,通过多个从节点分担读负载,可以大大提高Redis服务器的并发量.
4. 高可用(集群)基石:除了上诉作用以外,主从复制还是烧饼和集群能够实施的基础,因此说主从复制是Redis高可用的基础.

##  缓存穿透

>  什么是缓存穿透？

缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。

#### [有哪些解决办法？]()

最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。

**1）缓存无效 key**

如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： `SET key value EX 10086` 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。

另外，这里多说一嘴，一般情况下我们是这样设计 key 的： `表名:列名:主键名:主键值` 。

**2）布隆过滤器**

布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。

具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。

但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： **布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

*为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！*

我们先来看一下，**当一个元素加入布隆过滤器中的时候，会进行哪些操作：**

1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

我们再来看一下，**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：**

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

然后，一定会出现这样一种情况：**不同的字符串可能哈希出来的位置相同。** （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）

更多关于布隆过滤器的内容可以看：[《不了解布隆过滤器？一文给你整的明明白白！》](https://github.com/Snailclimb/JavaGuide/blob/master/docs/dataStructures-algorithms/data-structure/bloom-filter.md) 

## [缓存雪崩]()

> 什么是缓存雪崩？

我发现缓存雪崩这名字起的有点意思，哈哈。

实际上，缓存雪崩描述的就是这样一个简单的场景：**缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。** 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。

举个例子：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。

还有一种缓存雪崩的场景是：**有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。** 这样的情况，有下面几种解决办法：

举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。

#### [有哪些解决办法？]()

**针对 Redis 服务不可用的情况：**

1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
2. 限流，避免同时处理大量的请求。

**针对热点缓存失效的情况：**

1. 设置不同的失效时间比如随机设置缓存的失效时间。
2. 缓存永不失效。

## Redis是如何判断数据是否过期的呢？

Redis 通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。

## 过期的数据的删除策略了解么？

如果假设你设置了一批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进行删除的呢？

常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：

1. **惰性删除** ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。
2. **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。

定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采用的是 **定期删除+惰性/懒汉式删除** 。

但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就Out of memory了。

怎么解决这个问题呢？答案就是： **Redis 内存淘汰机制。**

## Redis 内存淘汰机制了解么？

Redis 提供 6 种数据淘汰策略：

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key